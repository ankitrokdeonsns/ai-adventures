{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./titanic_train.csv')\n",
    "test_data = pd.read_csv('./titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = train_data['Age'].mean()\n",
    "def process_age(data):\n",
    "    return pd.DataFrame(data['Age'].fillna(mean_age), columns = ['Age'])\n",
    "new_age = process_age(train_data)\n",
    "new_age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_embarked = train_data['Embarked'].mode()[0]\n",
    "new_embarked = pd.DataFrame(train_data['Embarked'].fillna(mode_embarked), columns = ['Embarked'])\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "embarked_label_encoder = LabelEncoder()\n",
    "embarked_integer_encoded = embarked_label_encoder.fit_transform(new_embarked)\n",
    "embarked_integer_encoded = embarked_integer_encoded.reshape(len(embarked_integer_encoded), 1)\n",
    "embarked_one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "embarked_one_hot_encoder.fit(embarked_integer_encoded)\n",
    "def process_embarked(data):\n",
    "    data = pd.DataFrame(data['Embarked'].fillna(mode_embarked), columns = ['Embarked'])\n",
    "    integer_encoded = embarked_label_encoder.transform(data['Embarked'])\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    labels = ['Embarked__' + str(i) for i in range(len(embarked_label_encoder.classes_))]\n",
    "    return pd.DataFrame(embarked_one_hot_encoder.transform(integer_encoded), columns = labels)\n",
    "new_embarked = process_embarked(train_data)\n",
    "new_embarked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(train_data['Sex'])\n",
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "def process_sex(data):\n",
    "    int_encoded = label_encoder.transform(data['Sex'])\n",
    "    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
    "    col_names = ['Sex__' + str(i) for i in range(len(label_encoder.classes_))]\n",
    "    return pd.DataFrame(one_hot_encoder.transform(int_encoded), columns = col_names)\n",
    "process_sex(train_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    processed_age = process_age(data)\n",
    "    processed_embarked = process_embarked(data)\n",
    "    processed_sex = process_sex(data)\n",
    "    processed = pd.DataFrame()\n",
    "    processed = pd.concat([processed\n",
    "                           , processed_age\n",
    "                           , processed_embarked\n",
    "                           , processed_sex\n",
    "                           , data[['Pclass', 'SibSp', 'Parch', 'Fare']]], axis = 1)\n",
    "    return processed\n",
    "train_processed = process(train_data)\n",
    "train_labels = train_data['Survived']\n",
    "train_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = process(test_data)\n",
    "test_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cross_val_score(LogisticRegression(), train_processed, train_labels, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the model we need to scale features, specially `Age` and `Fare`.\n",
    "We have 3 options.\n",
    "* ### standard scaling: assumes the data to be normally distributed\n",
    "* ### min-max scaling: sensitive to outliers\n",
    "* ### robust scaling: uses inter-quantile range, less sensitive to outliers\n",
    "\n",
    "Hence we need to find if the data is normally distributed or if there are outliers in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.distplot(train_processed[['Age']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age` does not seem normally ditributed. It is worth noting that `Age` had missing values and we imputed the same with the `mean`. Number of missing values were 891 - 714 = 177 which is a large proportion of data. So imputing blindly with mean might not be the best strategy. We will try to fix this later. Let us check if it has outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(train_processed[['Age']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are a lot of outliers. Hence we should use robust scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "age_scaler = RobustScaler()\n",
    "age_scaler.fit_transform(train_processed[['Age']])\n",
    "def process_age_2(data):\n",
    "    return pd.DataFrame(age_scaler.transform(data[['Age']]), columns = ['Age'])\n",
    "process_age_2(train_processed).describe()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing makes some age values as negative and the mean age to be 0. This does not sync very well with real world, but we will see if the model is affected by this.\n",
    "\n",
    "Let us turn to `Fare`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.distplot(train_processed[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fare` seems to be a skewed distribution. Lets also look for presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(train_processed[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly there are outliers in this data. Let us use robust scaling again and compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_scaler = RobustScaler()\n",
    "fare_scaler.fit_transform(train_processed[['Fare']])\n",
    "\n",
    "def process_fare_2(data):\n",
    "    return pd.DataFrame(fare_scaler.transform(data[['Fare']]), columns = ['Fare'])\n",
    "\n",
    "process_fare_2(train_processed).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = train_data['Age'].mean()\n",
    "def process_age(data):\n",
    "    return pd.DataFrame(data['Age'].fillna(mean_age), columns = ['Age'])\n",
    "\n",
    "def process_2(data):\n",
    "    processed_age = process_age(data)\n",
    "    processed_age = process_age_2(processed_age)\n",
    "    processed_fare = process_fare_2(data)\n",
    "    processed_embarked = process_embarked(data)\n",
    "    processed_sex = process_sex(data)\n",
    "    processed = pd.DataFrame()\n",
    "    processed = pd.concat([processed\n",
    "                           , processed_age\n",
    "                           , processed_fare\n",
    "                           , processed_embarked\n",
    "                           , processed_sex\n",
    "                           , data[['Pclass', 'SibSp', 'Parch']]], axis = 1)\n",
    "    return processed\n",
    "\n",
    "train_processed_2 = process_2(train_data)\n",
    "test_processed_2 = process_2(test_data)\n",
    "print(train_processed_2.describe())\n",
    "cross_val_score(LogisticRegression(), train_processed_2, train_labels, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processing has reduced the accuracy of our model. But remember out imputation of the age may not be right from the first place. And we have not removed outliers.\n",
    "\n",
    "We need to diagnose if model is underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, valX, trainY, valY = train_test_split(train_processed, train_labels, test_size = 0.2, random_state = 73, shuffle = True)\n",
    "model = LogisticRegression()\n",
    "model.fit(trainX, trainY)\n",
    "print('training score:', model.score(trainX, trainY))\n",
    "print('validation score:', model.score(valX, valY))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valY, model.predict(valX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall when passenger survived is low. Model is biased towards predicting non survival of passenger. Training score is similar to validation score. This is a sign of underfitting.\n",
    "Let us add more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip()).unique()\n",
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Dona\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}\n",
    "def get_title(name):\n",
    "    title = name.split(',')[1].split('.')[0].strip()\n",
    "    return title_dictionary[title]\n",
    "\n",
    "title_label_encoder = LabelEncoder()\n",
    "title_integer_encoded = title_label_encoder.fit_transform(train_data['Name'].map(get_title))\n",
    "title_one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "title_integer_encoded = title_integer_encoded.reshape(len(title_integer_encoded), 1)\n",
    "title_onehot_encoded = title_one_hot_encoder.fit_transform(title_integer_encoded)\n",
    "\n",
    "def process_name(data):\n",
    "    titles = data['Name'].map(get_title)\n",
    "    integer_encoded = title_label_encoder.transform(titles)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    one_hot_encoded = title_one_hot_encoder.transform(integer_encoded)\n",
    "    col_names = ['Title__' + str(i) for i in range(len(title_label_encoder.classes_))]\n",
    "    return pd.DataFrame(one_hot_encoded, columns = col_names)\n",
    "\n",
    "process_name(train_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_mr = train_data[train_data['Name'].map(get_title) == 'Mr']['Age'].mean()\n",
    "mean_age_mrs = train_data[train_data['Name'].map(get_title) == 'Mrs']['Age'].mean()\n",
    "mean_age_miss = train_data[train_data['Name'].map(get_title) == 'Miss']['Age'].mean()\n",
    "mean_age_royalty = train_data[train_data['Name'].map(get_title) == 'Royalty']['Age'].mean()\n",
    "mean_age_officer = train_data[train_data['Name'].map(get_title) == 'Officer']['Age'].mean()\n",
    "mean_age_master = train_data[train_data['Name'].map(get_title) == 'Master']['Age'].mean()\n",
    "\n",
    "title_to_mean_age = {\n",
    "    'Mr': mean_age_mr\n",
    "    , 'Mrs': mean_age_mrs\n",
    "    , 'Miss': mean_age_miss\n",
    "    , 'Royalty': mean_age_royalty\n",
    "    , 'Officer': mean_age_officer\n",
    "    , 'Master': mean_age_master\n",
    "}\n",
    "import math\n",
    "def process_age_3(data):\n",
    "    ages = []\n",
    "    for idx, row in data.iterrows():\n",
    "        if math.isnan(row['Age']):\n",
    "            ages.append(title_to_mean_age[get_title(row['Name'])])\n",
    "        else:\n",
    "            ages.append(row['Age'])\n",
    "    return pd.DataFrame(ages, columns = ['Age'])\n",
    "process_age_3(train_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_3(data):\n",
    "    processed_age = process_age_3(data)\n",
    "    processed_embarked = process_embarked(data)\n",
    "    processed_sex = process_sex(data)\n",
    "    processed_name = process_name(data)\n",
    "    processed = pd.DataFrame()\n",
    "    processed = pd.concat([processed\n",
    "                           , processed_age\n",
    "                           , processed_embarked\n",
    "                           , processed_sex\n",
    "                           , processed_name\n",
    "                           , data[['Fare', 'Pclass', 'SibSp', 'Parch']]], axis = 1)\n",
    "    return processed\n",
    "train_processed_3 = process_3(train_data)\n",
    "test_processed_3 = process_3(test_data)\n",
    "cross_val_score(LogisticRegression(), train_processed_3, train_labels, cv = 5).mean()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, valX, trainY, valY = train_test_split(train_processed_3, train_labels, test_size = 0.2, random_state = 73, shuffle = True)\n",
    "model_3 = LogisticRegression()\n",
    "model_3.fit(trainX, trainY)\n",
    "print('training score:', model_3.score(trainX, trainY))\n",
    "print('validation score:', model_3.score(valX, valY))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valY, model_3.predict(valX)))\n",
    "print(model_3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_3.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Fare` column has very less weight. We can check how model performs by dropping that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_4 = train_processed_3.drop(['Fare'], axis = 1)\n",
    "print(cross_val_score(LogisticRegression(), train_processed_4, train_labels, cv = 5).mean() )\n",
    "model_4 = LogisticRegression()\n",
    "model_4.fit(train_processed_4, train_labels)\n",
    "print(classification_report(valY, model_4.predict(valX.drop(['Fare'], axis = 1))))\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved k fold cross validation slightly. Let us try by dropping age feature as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_5 = train_processed_3.drop(['Fare', 'Age'], axis = 1)\n",
    "print(cross_val_score(LogisticRegression(), train_processed_5, train_labels, cv = 5).mean() )\n",
    "model_5 = LogisticRegression()\n",
    "model_5.fit(train_processed_5, train_labels)\n",
    "print(classification_report(valY, model_5.predict(valX.drop(['Fare', 'Age'], axis = 1))))\n",
    "print(model_5.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_4 = test_processed_3.drop(['Fare'], axis = 1)\n",
    "predictions_4 = pd.DataFrame(model_4.predict(test_processed_4), columns = ['Survived'])\n",
    "results_4 = pd.concat([test_data[['PassengerId']], predictions_4], axis = 1)\n",
    "results_4.to_csv('output_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_5 = test_processed_3.drop(['Age', 'Fare'], axis = 1)\n",
    "predictions_5 = pd.DataFrame(model_5.predict(test_processed_5), columns = ['Survived'])\n",
    "results_5 = pd.concat([test_data[['PassengerId']], predictions_5], axis = 1)\n",
    "results_5.to_csv('output_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabins = train_data['Cabin'].fillna('U')\n",
    "cabins = cabins.map(lambda x: x[0])\n",
    "cabins.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_examples = valX[valY != model_5.predict(valX.drop(['Fare', 'Age'], axis = 1))]\n",
    "train_data.iloc[error_examples.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples above are misclassified examples from our validation set.\n",
    "I look into the data to find correlation between features and their survival.\n",
    "In these examples passengers of class 1 have always survived but we predicted them otherwise.\n",
    "Another interesting point to note is the dead people in these examples are all females.\n",
    "Most of these dead passengers have paid low ticket price.\n",
    "While designing the model we had dropped the `Fare` feature since the weight of this feature in our logistic regression model was very low and we concluded that the model is trying too had to incorporate this information.\n",
    "It might be a better idea if we categorize / discretize the fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0, 0.15, 0.3, 0.45, 0.6, 0.75, 1.0]\n",
    "_, fare_bins = pd.qcut(train_data['Fare'], q = quantiles, retbins = True)\n",
    "def process_fare(data):\n",
    "    fares = data['Fare'].fillna(data['Fare'].mean())\n",
    "    return pd.cut(fares, bins = fare_bins, labels = [1, 2, 3, 4, 5, 6], include_lowest = True).to_frame(name = 'Fare_class')\n",
    "fare_classes = process_fare(train_data)\n",
    "fare_classes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_4(data):\n",
    "    processed_age = process_age_3(data)\n",
    "    processed_embarked = process_embarked(data)\n",
    "    processed_sex = process_sex(data)\n",
    "    processed_name = process_name(data)\n",
    "    processed_fare = process_fare(data)\n",
    "    processed = pd.DataFrame()\n",
    "    processed = pd.concat([processed\n",
    "#                            , processed_age\n",
    "                           , processed_embarked\n",
    "                           , processed_sex\n",
    "                           , processed_name\n",
    "                           , processed_fare\n",
    "                           , data[['Pclass', 'SibSp', 'Parch']]], axis = 1)\n",
    "    return processed\n",
    "train_processed_4 = process_4(train_data)\n",
    "test_processed_4 = process_4(test_data)\n",
    "model_6 = LogisticRegression()\n",
    "model_6.fit(train_processed_4, train_labels)\n",
    "print(cross_val_score(model_6, train_processed_4, train_labels, cv = 5).mean())\n",
    "print(model_6.coef_)\n",
    "trainX, valX, trainY, valY = train_test_split(train_processed_4, train_labels, test_size = 0.2, random_state = 73, shuffle = True)\n",
    "print(classification_report(valY, model_6.predict(valX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_6 = process_4(test_data)\n",
    "print(test_data.describe())\n",
    "print(train_data['Fare'].describe())\n",
    "predictions_6 = pd.DataFrame(model_6.predict(test_processed_6), columns = ['Survived'])\n",
    "results_6 = pd.concat([test_data[['PassengerId']], predictions_6], axis = 1)\n",
    "results_6.to_csv('output_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
