{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "* Andrew Ng ML (course)[https://www.coursera.org/learn/machine-learning/]\n",
    "* Dataset suggestion from (here)[https://machinelearningmastery.com/standard-machine-learning-datasets/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this series is to serve as a handbook to those who are starting their journey in Machine Learning.\n",
    "Currently there is a lot of literature in academia as well as on the web that is frankly very overwhelming for a newcomer (like me).\n",
    "Also new blogposts and research paper titles have very complex heavy words which daunt a newcomer and makes it harder for them to learn about the field.\n",
    "In this series we will keep things simple and try to understand the concepts well.\n",
    "The focus is to present guidelines to make decisions during building a Machine Learning model.\n",
    "We will understand all these tricks of the trade by actually implementing stuff we will be talking about.\n",
    "Lets get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Setup\n",
    "Install Anaconda and launch Jupyter Notebook.\n",
    "Familiarize yourself with how to use jupyter notebook and get hello world working.\n",
    "No need to get into nitty gritty details of jupyter notebook.\n",
    "That we can do later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Loading data\n",
    "The first thing to do is get some data with us.\n",
    "As suggested in [this](https://machinelearningmastery.com/standard-machine-learning-datasets/) I have chosen PIMA Indians Diabetes dataset.\n",
    "#### Why have I chosen this dataset? Explain Here without too much jargon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we download the dataset this first thing is to load the dataset.\n",
    "As we can see we have a CSV file which is commonly used to send tabular data.\n",
    "We use pandas library to load this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/pima-indians-diabetes.data.csv')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I seems like the CSV file does not have any column names.\n",
    "Lets reload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/pima-indians-diabetes.data.csv', header = None)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sucessfully loaded data lets add meaningful column names to our dataset.\n",
    "This information is present on the page we downloaded the dataset from.\n",
    "For some other dataset which already have column names in them this step and the previous step would be optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['pregnant_count'\n",
    "                , 'glucose'\n",
    "                , 'blood_pressure'\n",
    "                , 'thickness'\n",
    "                , 'insulin'\n",
    "                , 'bmi'\n",
    "                , 'pedigree'\n",
    "                , 'age'\n",
    "                , 'class']\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting to know the dataset\n",
    "#### Find the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us in our data there are 768 rows and 9 columns.\n",
    "Our goal is to predict the `class` of a given row in the data from the other values in the row.\n",
    "These other values are called `features`.\n",
    "In this dataset we have 8 features from `pregnant_count` through `age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find number of distinct values in `class` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us there are only 2 classes in the dataset namely `1` and `0`.\n",
    "Hence this is a binary classification problem.\n",
    "As you are starting your journey into Machine Learning such problems are easier to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting to know your data a little more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The `describe` method tells us more information about our dataset.\n",
    "Initially you should pay attention to `count` for each column.\n",
    "It tells us how many values are present in that column.\n",
    "In this case there are 768 values in each column exactly equal to the number of rows in our dataset.\n",
    "In many cases there might be missing values in the dataset where the count of data in one or more columns will not be same as count of rows in the dataset.\n",
    "We will learn to deal with such missing values if present later.\n",
    "For now we dont need to worry about it.\n",
    "\n",
    "#### How to handle missing values from dataset? (Explain Later)\n",
    "\n",
    "One other thing to notice is all the values in our dataset are numerical values.\n",
    "In many datasets we might also have other kinds of values such as strings and categorical values.\n",
    "We will learn to deal the same later.\n",
    "\n",
    "#### How to handle strings and categorical data in the dataset? (Explain Later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to evaluate your predictions?\n",
    "The goal of building a prediction model (like the one we are building) is to do well on unseen data.\n",
    "The more accurate predictions are on unseen data the better is the model.\n",
    "The data that the model gets to see is known as training data sine it is the data with which the model gets trained to do predictions.\n",
    "The unseen data on which model has to predit and do well is known as testing data since it is the data model gets tested.\n",
    "Many datasets have separate training data and testing data.\n",
    "In our case it is not so.\n",
    "Hence we will reserve some data from our dataset as testing data.\n",
    "\n",
    "#### Assumption: distribution of training data and testing data should be the same.\n",
    "#### How big the testing data should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[['pregnant_count'\n",
    "        , 'glucose'\n",
    "        , 'blood_pressure'\n",
    "        , 'thickness'\n",
    "        , 'insulin'\n",
    "        , 'bmi'\n",
    "        , 'pedigree'\n",
    "        , 'age']]\n",
    "Y = data[['class']]\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X\n",
    "                                                , Y\n",
    "                                                , test_size = 0.2\n",
    "                                                , random_state = 73)\n",
    "print('trainX shape', trainX.shape)\n",
    "print('trainY shape', trainY.shape)\n",
    "print('testX shape', testX.shape)\n",
    "print('testY shape', testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We use `train_test_split` method from `scikit-learn` library to split our data into training data and testing data.\n",
    "This method expects the features and labels (classes) to be provided as arguments hence we extract them as X and Y first.\n",
    "We use 20% of the data as test data and rest as training data.\n",
    "`train_test_split` method randomly selects 80% of the data as training data and remaining 20% of the data as test data.\n",
    "In order to achieve repeatable results we provide `random_state` to this method.\n",
    "Finally we check the size of training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and Testing the model\n",
    "Now that we have prepared our data it is time to train our model with training data and test the same with testing data.\n",
    "As we have stated before this is a binary classification problem.\n",
    "A good starting algorithm for this problem is `Logistic Regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state = 73)\n",
    "model.fit(trainX, trainY)\n",
    "print('train accuracy', model.score(trainX, trainY))\n",
    "print('test accuracy', model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We first created an instance of `LogisticRegression` model.\n",
    "We provided `random_state` to achieve reproducible results.\n",
    "The `fit` method trains the model with training data.\n",
    "Finally we checked the preformane of the model using `score` method on training and testing data.\n",
    "The `score` method tells if we provided some examples to the trained model what fraction it got right during prediction.\n",
    "For training data it achieved 77% accuracy.\n",
    "This means after training the model could successfully classify 77% of the training examples.\n",
    "For testing data it achieved 77% accuracy.\n",
    "Congratulations! You have successfully built a machine learning model.\n",
    "Lets see how we can use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = testX.head(1)\n",
    "cls = testY.head(1)\n",
    "print(example)\n",
    "print('#' * 80)\n",
    "print('actual class')\n",
    "print(cls)\n",
    "print('#' * 80)\n",
    "print('prediction:', model.predict(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We provided first row from the test data as the input.\n",
    "Its actual class was `0`.\n",
    "Then we provided the same example to our model for prediction.\n",
    "The model correctly predicted the class of the example as `0`.\n",
    "The reason the prediction looks like an array with a single value in it is beacuse we provided the model an array that contained a single example for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What to do next?\n",
    "Now that we have trained our model with `Logistic Regression` and achieved 77% accuracy on the test data what can we do to improve our accuracy?\n",
    "To understand that we need to know how `Logistic Regression` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature scaling explain here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = pd.DataFrame(MinMaxScaler().fit_transform(data))\n",
    "data.columns = ['pregnant_count'\n",
    "                , 'glucose'\n",
    "                , 'blood_pressure'\n",
    "                , 'thickness'\n",
    "                , 'insulin'\n",
    "                , 'bmi'\n",
    "                , 'pedigree'\n",
    "                , 'age'\n",
    "                , 'class']\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 73)\n",
    "model.fit(trainX, trainY)\n",
    "print('train accuracy', model.score(trainX, trainY))\n",
    "print('test accuracy', model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### regularization\n",
    "### explain regularization here\n",
    "* by default `LogisticRegression` uses L2 loss\n",
    "### results without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noReg = LogisticRegression( C = 1e40\n",
    "                          , random_state = 73)\n",
    "                          \n",
    "noReg.fit(trainX, trainY)\n",
    "print('train accuracy', noReg.score(trainX, trainY))\n",
    "print('test accuracy', noReg.score(testX, testY))\n",
    "noReg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
