{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "features = pd.DataFrame(dataset.data)\n",
    "labels = pd.DataFrame(dataset.target)\n",
    "data = pd.concat([features, labels], axis = 1)\n",
    "data.columns = np.concatenate([dataset.feature_names, np.array(['class'])])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generally floating point values with various ranges. Lets look at datatypes of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total 30 features each with float values. Lets see if there is any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data. Lets scale features to standardize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No separate test data. Hence split data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features \\\n",
    ", test_features \\\n",
    ", train_labels \\\n",
    ", test_labels = train_test_split(scaled \\\n",
    "                                 , labels \\\n",
    "                                 , test_size = 0.2 \\\n",
    "                                 , random_state = 73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try multiple models to check their performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'lr': LogisticRegression() \\\n",
    "          , 'svm': SVC() \\\n",
    "          , 'dt': DecisionTreeClassifier() \\\n",
    "          , 'rf': RandomForestClassifier() \\\n",
    "          , 'knn': KNeighborsClassifier() \\\n",
    "          , 'nb': GaussianNB() \\\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use K fold cross validation to compare among models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    kfold = KFold(n_splits = 10, random_state = 73)\n",
    "    cv_results = cross_val_score(model, train_features, train_labels, cv = kfold, scoring = 'accuracy')\n",
    "    print(\"%s: %.4f %.4f\" % (name, cv_results.mean(), cv_results.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform hyperparameter tuning of best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.01\n",
    "print(\"%-10s %-10s %-10s\" % ('c', 'accuracy', 'variance'))\n",
    "while c <= 10:\n",
    "    model = LogisticRegression(C = c, random_state = 73)\n",
    "    kfold = KFold(n_splits = 10, random_state = 73)\n",
    "    cv_results = cross_val_score(model, train_features, train_labels, cv = kfold, scoring = 'accuracy')\n",
    "    print(\"%-10.2f %-10.4f %-10.4f\" % (c, cv_results.mean(), cv_results.std()))\n",
    "    c = c * 3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not much improvement with Logistic Regression. Maybe the model is not complex enough to learn more. Lets try the next best performing more complex model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%-10s %-10s %-10s %-10s\" % ('kernel', 'c', 'accuracy', 'variance'))\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    c = 0.01\n",
    "    while c <= 10:\n",
    "        model = SVC(C = c, kernel = k, random_state = 73)\n",
    "        kfold = KFold(n_splits = 10, random_state = 73)\n",
    "        cv_results = cross_val_score(model, train_features, train_labels, cv = kfold, scoring = 'accuracy')\n",
    "        print(\"%-10s %-10.2f %-10.4f %-10.4f\" % (kernel, c, cv_results.mean(), cv_results.std()))\n",
    "        c = c * 3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel choice did not matter much. We will use default RBF kernel. Best c value 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C = 0.09, random_state = 73)\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features)\n",
    "print('accuracy:', accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
