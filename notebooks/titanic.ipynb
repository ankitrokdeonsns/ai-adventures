{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set()\n",
    "sb.set_palette('Set1')\n",
    "plt.rcParams['figure.figsize'] = (11.7, 8.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/titanic_train.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 columns of various types int, object, float. Also there are some missing values.\n",
    "Lets look at how much data is missing from each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 columns have missing data. We will do something about this a little later.\n",
    "For now lets look at some samples from data and try to understand the columns with `object` as their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets look at the columns with object type.\n",
    "* `Name`: `string`\n",
    "* `Sex`: `string` most likely a categorical variable\n",
    "* `Ticket`: `string` seems like ticket ID\n",
    "* `Cabin`: `string` seems like cabin no. / room id\n",
    "* `Embarked`: `string` seems like code of station from which passenger embarked\n",
    "\n",
    "Another interesting thing to observe is `Age` is a float value and not integer. Not very common representation. We can try to deal with this later.\n",
    "\n",
    "Let try to find unique values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(\"%-20s %-10s %-10s\" %(col, data[col].dtype, data[col].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `PassengerId` has datatype of `int` and all are distinct values. This feature will not be very useful for modelling.\n",
    "* `Survived` is the target value we need to predict\n",
    "* `Pclass` has 3 distinct `int` values. This defines passenger class.\n",
    "* `Sex` has only 2 distinct values.\n",
    "* `SibSp` are `int` values denoting with how many total siblings and spouse passenger is travelling.\n",
    "* `Parch` are `int` values denoting with how many total parents and children passenger is travelling.\n",
    "* `Embarked` has 3 distinct values.\n",
    "* `Ticket`, `Fare`, `Cabin` and `Name` have a number of distinct values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step let us ignore columns with large number of missing values. And let us convert categorical data into their **One Hot** representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v1 = data[['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']]\n",
    "labels = data[['Survived']]\n",
    "\n",
    "embarked_mode = features_v1['Embarked'].mode()[0]\n",
    "print(embarked_mode)\n",
    "features_v1.fillna(value = {'Embarked': embarked_mode}, inplace = True)\n",
    "features_v1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v1 = pd.get_dummies(features_v1, columns = ['Sex', 'Embarked'])\n",
    "features_v1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features \\\n",
    ", test_features \\\n",
    ", train_labels \\\n",
    ", test_labels = train_test_split(features_v1, labels, test_size = 0.3, random_state = 73, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'lr': LogisticRegression() \\\n",
    "          , 'svm': SVC() \\\n",
    "          , 'dt': DecisionTreeClassifier() \\\n",
    "          , 'rf': RandomForestClassifier() \\\n",
    "          , 'knn': KNeighborsClassifier() \\\n",
    "          , 'nb': GaussianNB() \\\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%-10s %-10s %-10s %-10s\" % (\"model\", \"cv acc\", \"cv stddev\", \"train acc\"))\n",
    "for name, model in models.items():\n",
    "    kfold = KFold(n_splits = 10, random_state = 73)\n",
    "    cv_results = cross_val_score(model, train_features, train_labels, cv = kfold, scoring = 'accuracy')\n",
    "    model.fit(train_features, train_labels)\n",
    "    train_accuracy = accuracy_score(train_labels, model.predict(train_features))\n",
    "    print(\"%-10s %-10.4f %-10.4f %-10.4f\" % (name, cv_results.mean(), cv_results.std(), train_accuracy))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have not performed **feature scaling**.\n",
    "Let us do the same and see if it helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v2 = MinMaxScaler().fit_transform(features_v1)\n",
    "# print(pd.DataFrame(features_v2, columns = features_v1.columns).describe())\n",
    "\n",
    "def run_experiment(features):\n",
    "    train_features \\\n",
    "    , test_features \\\n",
    "    , train_labels \\\n",
    "    , test_labels = train_test_split(features, labels, test_size = 0.3, random_state = 73, shuffle = True)\n",
    "\n",
    "    models = {'lr': LogisticRegression() \\\n",
    "              , 'svm': SVC() \\\n",
    "              , 'dt': DecisionTreeClassifier() \\\n",
    "              , 'rf': RandomForestClassifier() \\\n",
    "              , 'knn': KNeighborsClassifier() \\\n",
    "              , 'nb': GaussianNB() \\\n",
    "             }\n",
    "\n",
    "    print(\"%-10s %-10s %-10s %-10s %-10s\" % (\"model\", \"cv acc\", \"cv stddev\", \"train acc\", \"overfitting\"))\n",
    "    for name, model in models.items():\n",
    "        kfold = KFold(n_splits = 10, random_state = 73)\n",
    "        cv_results = cross_val_score(model, train_features, train_labels, cv = kfold, scoring = 'accuracy')\n",
    "        model.fit(train_features, train_labels)\n",
    "        train_accuracy = accuracy_score(train_labels, model.predict(train_features))\n",
    "        print(\"%-10s %-10.4f %-10.4f %-10.4f %-10.4f\" % (name \\\n",
    "                                                         , cv_results.mean() \\\n",
    "                                                         , cv_results.std() \\\n",
    "                                                         , train_accuracy \\\n",
    "                                                         , train_accuracy - cv_results.mean() \\\n",
    "                                                        ))\n",
    "\n",
    "run_experiment(features_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall train accuracy is around 80%. \n",
    "Decision Tree and Random Forest seem to have more overfitting compared to other models. \n",
    "We **assume** that this accuracy is unacceptable and models are currently **underfitting**.\n",
    "To fix this underfitting **we need more and better features**.\n",
    "To derive these features **we need to look at data**. We will do some **EDA** on complete available training data.\n",
    "\n",
    "#### We also assume that the test data has similar distribution as training data. But we will need to TEST THAT LATER. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first thing** we should look at is the distribution of classes to ensure there is no **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Survived'].value_counts() / data.shape[0])\n",
    "sb.countplot(x = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The class distribution is 62% and 38%. Not very imbalanced. \n",
    "* If needed we can **adjust class weights** if the model permits. **TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next feature we look at is **Pclass**.\n",
    "* This defines the class with which passenger travelled.\n",
    "* As already seen this has only 3 distinct values.\n",
    "* Lets see how passenger class relates to passenger survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x = 'Pclass', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Significant number of passengers of class 3 did not survive\n",
    "* more passengers of class 1 survived\n",
    "* so passenger class seems to be a very important feature.\n",
    "* to help the models even more we should **One Hot encode** this feature. **TODO**\n",
    "\n",
    "Next lets look at `Sex` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x = 'Sex', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More females survived.\n",
    "* significantly high males did not survive.\n",
    "* Important feature to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Parch` denotes with total no. of parents and children person is travelling with.\n",
    "* `SibSp` denotes with total no. of siblings and spouses person is travelling with.\n",
    "* Lets observe how they relate to survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x = 'Parch', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x = 'SibSp', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* more persons travelling alone did not survive\n",
    "* persons with less than or equal to 3 total parents and children had better chances for survival\n",
    "* persons with more than 3 parents and children were very less and did not survive\n",
    "* can create features **alone**, **small parch**, and **large parch** based on these observations **TODO**\n",
    "\n",
    "\n",
    "* persons with a 1 SibSp survived more\n",
    "* persons with 2 SibSp had survived equally as they did not survive\n",
    "* many persons with more than 3 SibSp did not survive\n",
    "* can create features **alone**, **small sibsp** and **large sibsp** based on these observations **TODO**\n",
    "\n",
    "We can also build a `Family Size` for a person using `Parch` and `SibSp`.\n",
    "Lets see how that relates to survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['familySize'] = data['Parch'] + data['SibSp']\n",
    "sb.countplot(x = 'familySize', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* persons small families with less than 4 members survived more\n",
    "* persons with large families with did not survive more\n",
    "* we can create **small family** and **large family** as features **TODO**\n",
    "\n",
    "\n",
    "Lets look at `Embarked` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x = 'Embarked', hue = 'Survived', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* people who embarked on `C` survived more\n",
    "* people who embarked on `S` died more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create features based on these initial observations and check the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v3 = pd.get_dummies(features_v1, columns = ['Pclass'])\n",
    "features_v3['familySize'] = features_v3['Parch'] + features_v3['SibSp']\n",
    "features_v3['alone'] = features_v3['familySize'].map(lambda x: 1 if x == 0 else 0)\n",
    "features_v3['smallFamily'] = features_v3['familySize'].map(lambda x: 1 if 0 < x < 4 else 0)\n",
    "features_v3['largeFamily'] = features_v3['familySize'].map(lambda x: 1 if x >= 4 else 0)\n",
    "features_v3['smallParch'] = features_v3['Parch'].map(lambda x: 1 if 0 < x < 4 else 0)\n",
    "features_v3['largeParch'] = features_v3['Parch'].map(lambda x: 1 if x >= 4 else 0)\n",
    "features_v3['smallSibSp'] = features_v3['SibSp'].map(lambda x: 1 if 0 < x < 3 else 0)\n",
    "features_v3['largeSibSp'] = features_v3['SibSp'].map(lambda x: 1 if x >= 3 else 0)\n",
    "features_v3 = pd.DataFrame(MinMaxScaler().fit_transform(features_v3), columns = features_v3.columns)\n",
    "features_v3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(features_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have not looked at `Name`, `Fare`, `Age` and `Cabin`.\n",
    "\n",
    "`Fare` has no missing values. So lets look at that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.kdeplot(data[data['Survived'] == 0]['Fare'], label = 'Died')\n",
    "sb.kdeplot(data[data['Survived'] == 1]['Fare'], label = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More people who paid lower fares died\n",
    "* many people paid low fares. hence data seems skewed. we can try **log transformation** to reduce this skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.kdeplot(np.log(data[data['Survived'] == 0]['Fare']), label = 'Died')\n",
    "sb.kdeplot(np.log(data[data['Survived'] == 1]['Fare']), label = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems much more discreminative now. Lets add this feature and see how model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_features = pd.concat([data['Fare'], np.log(data['Fare'] + 1)], axis = 1)\n",
    "fare_features.columns = ['Fare', 'logFare']\n",
    "fare_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fare`s are not in same scale. Lets perform `Standard Scaling` on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_features_scaled = pd.DataFrame(StandardScaler().fit_transform(fare_features), columns = fare_features.columns)\n",
    "fare_features_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v4 = pd.concat([features_v3, fare_features_scaled], axis = 1)\n",
    "features_v4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(features_v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree and random forest are overfitting. We will handle it later. **TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a few names and see if we can extract some information out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* every name seems to have a title\n",
    "* few names have some names in brackets. these seem like maiden names of females. we can check if Mrs title and presence of maiden name are correlated\n",
    "* we can check how titles are related to survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(name):\n",
    "    return name.split(',')[1].split('.')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(data['Name'].map(extract_title).values, columns = ['Title'])\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how many distinct title are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Mlle`, `Ms`, `Lady` seem to be referring to women. We can verify by their `Sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.concat([data[['Name', 'Sex']], titles], axis = 1)\n",
    "people[(people['Title'] == 'Mlle') | (people['Title'] == 'Ms') | (people['Title'] == 'Lady')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how survival relates to title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_survival = pd.concat([data[['Survived']], titles], axis = 1)\n",
    "sb.countplot(x = 'Title', hue = 'Survived', data = title_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most people with `Mr` title died\n",
    "* `Mrs`, `Miss` and `Master` had better survival.\n",
    "* The data for other titles is very little. Lets try dropping frequent titles and check survival of other titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = title_survival[title_survival['Title'] != 'Mr']\n",
    "filtered = filtered[filtered['Title'] != 'Mrs']\n",
    "filtered = filtered[filtered['Title'] != 'Miss']\n",
    "filtered = filtered[filtered['Title'] != 'Master']\n",
    "sb.countplot(x = 'Title', hue = 'Survived', data = filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* all `Rev` died\n",
    "* Officers `Dr`, `Major`, `Col`, `Capt` died\n",
    "* `Mme`, `Ms`, `Mlle` are missspllings for `Miss` they survived\n",
    "* Royalty `Don`, `Lady`, `Sir`, `Countess`, `Jonkheer` survived more.\n",
    "* Lets check survival on basis of such groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Dona\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}\n",
    "new_titles = pd.DataFrame(titles['Title'].map(title_dictionary), columns = ['Title'])\n",
    "new_title_survival = pd.concat([data[['Survived']], new_titles], axis = 1)\n",
    "sb.countplot(x = 'Title', hue = 'Survived', data = new_title_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v5 = pd.concat([features_v4, pd.get_dummies(new_titles)], axis = 1)\n",
    "features_v5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(features_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some improvement in model. So title was an important feature\n",
    "* Lets also check if we didnt combine the title how did the models performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v6 = pd.concat([features_v4, pd.get_dummies(titles)], axis = 1)\n",
    "run_experiment(features_v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minor accuracy drop. We will continue to use combined titles\n",
    "* Lets now check how `Cabin` relates to survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_survival = data[['Cabin', 'Survived']]\n",
    "cabin_survival.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cabin seems to start with a uppercase letter. Lets see how many distinct such values are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_survival.dropna()['Cabin'].map(lambda x: x[0]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets replace `NaN` values with letter `X` and check survival against cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_survival.fillna('X', inplace=True)\n",
    "cabin_survival['Cabin'] = cabin_survival['Cabin'].map(lambda x: x[0])\n",
    "sb.countplot(x = 'Cabin', hue = 'Survived', data = cabin_survival[cabin_survival['Cabin'] != 'X'].sort_values('Cabin'))\n",
    "plt.show()\n",
    "sb.countplot(x = 'Cabin', hue = 'Survived', data = cabin_survival.sort_values('Cabin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cabin` seems to be an important feature. Lets add it to our features and check model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v7 = pd.concat([features_v5, pd.get_dummies(cabin_survival[['Cabin']])], axis = 1)\n",
    "features_v7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(features_v7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar performance. Later we will look at feature importance and see which features we should keep.\n",
    "Finally lets look at `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_survival = data[['Age', 'Survived']]\n",
    "sb.kdeplot(age_survival[age_survival['Survived'] == 0]['Age'], label = 'Died')\n",
    "sb.kdeplot(age_survival[age_survival['Survived'] == 1]['Age'], label = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Relatively similar behavior\n",
    "* Better chances of survival when age is less than about 10\n",
    "* We observed `Master` as a title earlier. Lets look at age range for that title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_age = pd.concat([people, data['Age']], axis = 1).dropna()\n",
    "title_age[title_age['Title'] == 'Master'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Max age for master title is 12. Lets check the same for girls as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_age[(title_age['Sex'] == 'female') & (title_age['Age'] <= 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every title is `Miss`. Lets look at titles for age above 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_age[(title_age['Sex'] == 'female') & (title_age['Age'] > 12) & (title_age['Title'] == 'Miss')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can impute missing age values by mean values by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_titles['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_by_title = {}\n",
    "for title in new_titles['Title'].unique():\n",
    "    mean_age_by_title[title] = title_age[title_age['Title'] == title].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
